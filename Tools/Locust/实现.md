我再把情景完善一下，给我写出服务端和客户端 
1. 环境：容器单机配置resources: requests: cpu: 0.1 memory: 1Gi limits: cpu: 2 memory: 4Gi
2. 处理每个请求大概5分钟 
3. locust 模拟客户端并发请求 FASTAPI服务 
4. 服务端接收到请求后第一时间返回消息，但是任务后台处理（5分钟那个） 
5. 等到处理完，通过websocket返回消息给客户端，带任务ID和任务处理结果 
6. 需要随机不稳定模拟：断线重连、超时 
7. 需要计算QPS 
8. 选择你觉得合理的并发、异步工具（队列, backgroundtask,semaphor, 线程池等等）


你完全正确，关于 **`BackgroundTasks`** 和 **长时间任务** 的问题，我之前的建议并不完全合适。在处理像你描述的 **5分钟左右的任务** 时，**`BackgroundTasks`** 由于是基于事件循环的异步框架，它并不适合用于长时间运行的任务，尤其是当任务可能会阻塞事件循环时。对于长时间运行的任务，尤其是 I/O 密集型的任务，应该使用更适合的并发执行模型，比如 **线程池** 或 **进程池**，这样可以避免影响到 FastAPI 的主事件循环。

### 为什么 `BackgroundTasks` 不适合长时间任务？

**`BackgroundTasks`** 是基于异步的事件循环，在后台任务中运行时，它依赖于当前的事件循环。如果你的任务需要很长时间（如 5 分钟），它会阻塞这个事件循环，使得其他请求的响应被延迟，导致系统的性能下降。尤其是当请求量很大时，**`BackgroundTasks`** 会逐渐成为瓶颈。

对于你这样的场景，任务本身并不复杂，但执行时间较长，且你希望后台处理不影响主请求流，**线程池** 或 **进程池** 可能是更合适的选择。

### 线程池 vs 进程池

* **线程池**：适用于 I/O 密集型任务。由于 Python 的 **全局解释器锁 (GIL)**，它在 CPU 密集型任务上表现较差，但对于任务中涉及大量等待外部资源（如 API 调用、数据库查询）的场景，线程池能非常有效地提高并发能力。

* **进程池**：适用于 **CPU 密集型任务**，每个进程有独立的 GIL，因此多个进程可以并行执行 CPU 密集型计算。

### 方案优化：使用线程池来处理长时间的后台任务

我们可以使用 **`ThreadPoolExecutor`** 来处理后台的长时间任务，从而避免阻塞事件循环。这样，FastAPI 可以继续处理其他请求，而长时间的任务在独立的线程中执行。

### 优化后的实现方案

#### 1. 服务端实现（FastAPI）

在这个方案中，我们使用 **`ThreadPoolExecutor`** 来管理后台任务的执行。

```python
from fastapi import FastAPI, BackgroundTasks, WebSocket, WebSocketDisconnect
import time
import random
import uuid
import asyncio
from concurrent.futures import ThreadPoolExecutor

app = FastAPI()

# 存储任务结果
task_results = {}
active_connections = {}

# 创建线程池执行器
executor = ThreadPoolExecutor(max_workers=10)  # 限制最大并发任务数为 10

# 模拟耗时任务（5分钟）
def long_task(task_id: str):
    """模拟一个耗时的任务（5分钟）"""
    task_results[task_id] = {"status": "processing", "result": f"Task {task_id} is being processed."}
    time.sleep(300)  # 模拟 5 分钟的任务
    # 模拟随机错误：断线重连、超时
    if random.random() < 0.2:
        task_results[task_id] = {"status": "failed", "result": "Task failed due to network error."}
    else:
        task_results[task_id] = {"status": "completed", "result": f"Task {task_id} completed successfully."}
    
    # 任务完成后通知 WebSocket 客户端
    if task_id in active_connections:
        asyncio.create_task(notify_websocket(active_connections[task_id], task_id))

# WebSocket 连接
async def notify_websocket(connection: WebSocket, task_id: str):
    """通过 WebSocket 向客户端推送任务结果"""
    try:
        await connection.send_json({
            "task_id": task_id,
            "status": task_results[task_id]
        })
    except WebSocketDisconnect:
        active_connections.pop(task_id, None)
        print(f"WebSocket disconnected for task {task_id}")

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket 处理客户端连接"""
    await websocket.accept()
    task_id = str(uuid.uuid4())  # 生成唯一任务 ID
    active_connections[task_id] = websocket
    
    # 客户端连接成功后，启动一个后台任务进行处理
    # 使用线程池来处理长时间运行的任务
    loop = asyncio.get_event_loop()
    loop.run_in_executor(executor, long_task, task_id)
    
    # 发送任务的初始状态
    await websocket.send_json({
        "task_id": task_id,
        "status": {"status": "processing", "result": "Task is being processed."}
    })

@app.get("/process/{task_id}")
async def process_item(task_id: str):
    """HTTP 接口启动后台任务"""
    # 使用线程池来处理长时间任务
    loop = asyncio.get_event_loop()
    loop.run_in_executor(executor, long_task, task_id)
    return {"message": f"Task {task_id} is being processed in the background."}
```

### 代码解释：

1. **`ThreadPoolExecutor`**：我们创建了一个 `ThreadPoolExecutor` 来处理后台的长时间任务，每个任务都会被放入线程池中执行，避免阻塞主事件循环。
2. **`long_task`**：模拟一个长时间的任务（5 分钟），并在完成后通过 WebSocket 通知客户端任务的结果。
3. **`notify_websocket`**：任务完成后，通过 WebSocket 向客户端推送任务的处理结果。
4. **`websocket_endpoint`**：WebSocket 连接建立后，启动一个线程池中的任务来异步处理该任务，并通过 WebSocket 向客户端返回任务的初始状态。

### 2. 客户端实现（Locust）

#### Locust 客户端代码（`locustfile.py`）

```python
from locust import HttpUser, task, between
import websocket
import threading
import json
import time
import random

class UserBehavior(HttpUser):
    wait_time = between(0.1, 0.5)  # 模拟请求间隔
    task_id = None  # 存储任务ID

    @task
    def start_task(self):
        """向 FastAPI 服务端发起 HTTP 请求，启动任务"""
        self.client.get("/process/1")
        self.task_id = "1"  # 假设任务 ID 是 1
        # 启动一个线程来通过 WebSocket 连接服务端
        threading.Thread(target=self.connect_websocket, args=(self.task_id,)).start()

    def connect_websocket(self, task_id):
        """WebSocket 连接到 FastAPI 服务端，接收任务结果"""
        ws = websocket.create_connection("ws://localhost:8000/ws")
        print(f"Connecting to WebSocket for task {task_id}")
        
        # 重试机制：模拟断线重连、超时
        retries = 0
        while retries < 5:
            try:
                # 等待 WebSocket 发送任务结果
                response = ws.recv()
                data = json.loads(response)
                if data["task_id"] == task_id:
                    print(f"Received result for task {task_id}: {data['status']['result']}")
                    ws.close()  # 任务完成，关闭连接
                    break
            except websocket.WebSocketConnectionClosedException:
                print(f"WebSocket connection closed unexpectedly, retrying... ({retries+1}/5)")
                retries += 1
                time.sleep(2)  # 重试间隔
                ws = websocket.create_connection("ws://localhost:8000/ws")  # 重新连接 WebSocket

            if retries == 5:
                print(f"Task {task_id} failed due to WebSocket connection issues.")

    def on_start(self):
        """Locust 客户端启动时的初始化行为"""
        print("Client started.")

    def on_stop(self):
        """Locust 客户端停止时的清理行为"""
        print("Client stopped.")
```

### 代码解释：

1. **`start_task`**：每次 Locust 用户模拟的请求会调用 `/process/1`，并启动一个线程通过 WebSocket 接收任务结果。
2. **`connect_websocket`**：模拟 WebSocket 客户端与 FastAPI 服务器连接，接收任务的处理结果。处理 WebSocket 断线重连和超时。

### 部署与运行

1. **启动 FastAPI 服务**：
   将 FastAPI 服务端代码保存为 `app.py`，并启动服务：

   ```bash
   uvicorn app:app --reload
   ```

2. **启动 Locust 压力测试**：
   安装 Locust 并运行客户端：

   ```bash
   pip install locust
   locust -f locustfile.py
   ```

3. 打开浏览器，访问 Locust 提供的 Web 界面：

   ```
   http://localhost:8089
   ```

   在 Web 界面中，设置并发用户数（Number of total users to simulate）和每秒启动的用户数（Hatch rate），然后点击 **Start swarming** 开始测试。

### 总结

* **FastAPI 服务端**：我们使用 **线程池** 来处理长时间运行的任务，确保不会阻塞主事件循环，同时通过 **WebSocket** 推送任务结果。
* **Locust 客户端**：模拟并发请求，使用 **WebSocket** 连接获取任务结果，并处理 **断线重连** 和 **超时** 情况。
* **QPS 计算**：通过 Locust 的 Web 界面实时计算 QPS，确保系统能够承载并发负载。

通过这种方案，既能高效处理长时间运行的任务，又能保证主事件循环不被阻塞，适合在单机容器环境中运行。
